{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1iSADVSlLJ4zDC_Ex5Ym8uFK1-f47qPNf",
      "authorship_tag": "ABX9TyOmUpTi19OTuQbO3zyi43Uk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manasarthak/Feature-Extraction-and-Electrode-Selection-for-Electroencephalogram-Based-emotion-classification/blob/main/Parallel_Bi_LSTM_Based_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.utils import class_weight,shuffle\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#importing layers\n",
        "from keras.layers import Input,LSTM,BatchNormalization,Dropout,Dense,Activation,concatenate\n",
        "from keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ],
      "metadata": {
        "id": "V-_RJyF-o2Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=np.load('/content/drive/MyDrive/DEAP/extracted_features/'+'fea.npy',allow_pickle=True);\n",
        "ArLabels=np.load('/content/drive/MyDrive/DEAP/arousal/'+'all_arousal_labels.npy',allow_pickle=True);\n",
        "ValLabels=np.load('/content/drive/MyDrive/DEAP/valence/'+'all_valence_labels.npy',allow_pickle=True);"
      ],
      "metadata": {
        "id": "9jsY6duNpGUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def channel_accuracy(data, labels):\n",
        "    # Model accuracy score with default hyperparameters i.e C=1, kernel=rbf, gamma=auto\n",
        "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(data, labels, test_size=0.15, random_state=42)\n",
        "    svc = SVC()\n",
        "    svc.fit(Xtrain, Ytrain)\n",
        "    Ypred = svc.predict(Xtest)\n",
        "    return accuracy_score(Ytest, Ypred)\n",
        "\n",
        "# Assuming dataset and labels are defined elsewhere\n",
        "for i in range(32):\n",
        "    d1 = dataset[:, i:i+1, :]\n",
        "    d1 = d1.reshape(1280, 6400)\n",
        "    acc = channel_accuracy(d1, labels)\n",
        "    print(\"Channel accuracy of channel no. \", i, \" is \", acc)\n"
      ],
      "metadata": {
        "id": "owPQHwehTV52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(data, labels, selected_indices):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.05, random_state=6)\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
        "    x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n",
        "\n",
        "    x_train_selected = [x_train[:, i, :].reshape(x_train.shape[0], 1, x_train.shape[-1]) for i in selected_indices]\n",
        "    x_test_selected = [x_test[:, i, :].reshape(x_test.shape[0], 1, x_test.shape[-1]) for i in selected_indices]\n",
        "\n",
        "    return x_train_selected, x_test_selected\n",
        "\n",
        "# Assuming dataset and labels are defined elsewhere\n",
        "selected_indices = [0, 1, 2, 3, 7, 8, 9, 15, 17, 18, 21, 28]\n",
        "\n",
        "x_train_selected, x_test_selected = process_data(dataset, labels, selected_indices)\n",
        "\n",
        "# Now x_train_selected and x_test_selected contain the transformed data\n",
        "# You can access them using x_train_selected[0], x_train_selected[1], etc."
      ],
      "metadata": {
        "id": "6lPz4c9XqT82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "for i in range(len(selected_indices)):\n",
        "    channel_input = Input(shape=(ip1, ip2))\n",
        "    lstm = LSTM(lstm_no, activation=act1)(channel_input)\n",
        "    b = BatchNormalization()(lstm)\n",
        "    drop = Dropout(dr)(b)\n",
        "    dense = Dense(dense1, activation=act2)(drop)\n",
        "    dense = BatchNormalization()(dense)\n",
        "    dense = Dropout(dr)(dense)\n",
        "\n",
        "    inputs.append(channel_input)\n",
        "    outputs.append(dense)\n",
        "\n",
        "concatenated = concatenate(outputs, axis=-1)\n",
        "x = Dense(12, activation='relu')(concatenated)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "x = Dense(12, activation='tanh')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=output)\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train_selected, y=y_train, epochs=500, batch_size=128,\n",
        "                    validation_data=(x_test_selected, y_test))\n",
        "print(\"Highest accuracy: \" + str(max(history.history['val_accuracy'])))\n"
      ],
      "metadata": {
        "id": "CvBX6LyYUGfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ip1 = 1   # Example value for the first input dimension\n",
        "ip2 = 24  # Example value for the second input dimension\n",
        "bi_lstm_no = 24\n",
        "dense1 = 24\n",
        "act1 = 'relu'\n",
        "act2 = 'relu'\n",
        "dr = 0.2"
      ],
      "metadata": {
        "id": "ZeJez7-Ho2Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "for i in range(len(selected_indices)):\n",
        "    channel_input = Input(shape=(ip1, ip2))\n",
        "    bilstm = Bidirectional(LSTM(bi_lstm_no, activation=act1))(channel_input)\n",
        "    b = BatchNormalization()(bilstm)\n",
        "    drop = Dropout(dr)(b)\n",
        "    dense = Dense(dense1, activation=act2)(drop)\n",
        "    dense = BatchNormalization()(dense)\n",
        "    dense = Dropout(dr)(dense)\n",
        "\n",
        "    inputs.append(channel_input)\n",
        "    outputs.append(dense)\n",
        "\n",
        "concatenated = concatenate(outputs, axis=-1)\n",
        "x = Dense(12, activation='relu')(concatenated)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "x = Dense(12, activation='tanh')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=output)\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x=x_train_selected, y=y_train, epochs=500, batch_size=128,\n",
        "                    validation_data=(x_test_selected, y_test))\n",
        "print(\"Highest accuracy: \" + str(max(history.history['val_accuracy'])))"
      ],
      "metadata": {
        "id": "2Xwne21L3501"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='model_val_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqSsfzUWo2Ig",
        "outputId": "0295be08-4d67-41b9-8087-96ea82588cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Barycenters are loaded\n"
          ]
        }
      ]
    }
  ]
}